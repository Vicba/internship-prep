{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2f8219fc-2989-4d98-9774-748f7da43bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import Sequence, List\n",
    "\n",
    "from llama_index.llms import OpenAI, ChatMessage\n",
    "from llama_index.tools import BaseTool, FunctionTool\n",
    "\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d2f8b5b8-b40d-4d3f-bc51-d34c789bd7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiple two integers and returns the result integer\"\"\"\n",
    "    return a * b\n",
    "\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Add two integers and returns the result integer\"\"\"\n",
    "    return a + b\n",
    "\n",
    "\n",
    "add_tool = FunctionTool.from_defaults(fn=add)\n",
    "multiply_tool = FunctionTool.from_defaults(fn=multiply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7641aab7-51f6-4948-9797-65b5241ef57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AIAgent:\n",
    "    def __init__(\n",
    "        self,\n",
    "        tools: Sequence[BaseTool] = [],\n",
    "        llm: OpenAI = OpenAI(temperature=0, model=\"gpt-3.5-turbo-0613\"),\n",
    "        chat_history: List[ChatMessage] = [],\n",
    "    ) -> None:\n",
    "        self._llm = llm\n",
    "        self._tools = {tool.metadata.name: tool for tool in tools}\n",
    "        self._chat_history = chat_history\n",
    "\n",
    "    def reset(self) -> None:\n",
    "        self._chat_history = []\n",
    "\n",
    "    def chat(self, message: str) -> str:\n",
    "        chat_history = self._chat_history\n",
    "        chat_history.append(ChatMessage(role=\"user\", content=message))\n",
    "        tools = [\n",
    "            tool.metadata.to_openai_tool() for _, tool in self._tools.items()\n",
    "        ]\n",
    "\n",
    "        ai_message = self._llm.chat(chat_history, tools=tools).message\n",
    "        additional_kwargs = ai_message.additional_kwargs\n",
    "        chat_history.append(ai_message)\n",
    "\n",
    "        tool_calls = ai_message.additional_kwargs.get(\"tool_calls\", None)\n",
    "        # parallel function calling is now supported\n",
    "        if tool_calls is not None:\n",
    "            for tool_call in tool_calls:\n",
    "                function_message = self._call_function(tool_call)\n",
    "                chat_history.append(function_message)\n",
    "                ai_message = self._llm.chat(chat_history).message\n",
    "                chat_history.append(ai_message)\n",
    "\n",
    "        return ai_message.content\n",
    "\n",
    "    def _call_function(self, tool_call: dict) -> ChatMessage:\n",
    "        id_ = tool_call.id\n",
    "        function_call = tool_call.function\n",
    "        tool = self._tools[function_call.name]\n",
    "        output = tool(**json.loads(function_call.arguments))\n",
    "        print(f\"> Calling tool: {function_call.name}\")\n",
    "        return ChatMessage(\n",
    "            name=function_call.name,\n",
    "            content=str(output),\n",
    "            role=\"tool\",\n",
    "            additional_kwargs={\n",
    "                \"tool_call_id\": id_,\n",
    "                \"name\": function_call.name,\n",
    "            },\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "94486c64-b328-4f6c-8d49-e291d0e0577e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:httpx:load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "DEBUG:httpx:load_verify_locations cafile='/etc/ssl/certs/ca-certificates.crt'\n",
      "load_verify_locations cafile='/etc/ssl/certs/ca-certificates.crt'\n",
      "load_verify_locations cafile='/etc/ssl/certs/ca-certificates.crt'\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'What is 2123 * 215123'}], 'model': 'gpt-3.5-turbo-0613', 'stream': False, 'temperature': 0.0, 'tools': [{'type': 'function', 'function': {'name': 'multiply', 'description': 'multiply(a: int, b: int) -> int\\nMultiple two integers and returns the result integer', 'parameters': {'type': 'object', 'properties': {'a': {'title': 'A', 'type': 'integer'}, 'b': {'title': 'B', 'type': 'integer'}}, 'required': ['a', 'b']}}}, {'type': 'function', 'function': {'name': 'add', 'description': 'add(a: int, b: int) -> int\\nAdd two integers and returns the result integer', 'parameters': {'type': 'object', 'properties': {'a': {'title': 'A', 'type': 'integer'}, 'b': {'title': 'B', 'type': 'integer'}}, 'required': ['a', 'b']}}}]}}\n",
      "Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'What is 2123 * 215123'}], 'model': 'gpt-3.5-turbo-0613', 'stream': False, 'temperature': 0.0, 'tools': [{'type': 'function', 'function': {'name': 'multiply', 'description': 'multiply(a: int, b: int) -> int\\nMultiple two integers and returns the result integer', 'parameters': {'type': 'object', 'properties': {'a': {'title': 'A', 'type': 'integer'}, 'b': {'title': 'B', 'type': 'integer'}}, 'required': ['a', 'b']}}}, {'type': 'function', 'function': {'name': 'add', 'description': 'add(a: int, b: int) -> int\\nAdd two integers and returns the result integer', 'parameters': {'type': 'object', 'properties': {'a': {'title': 'A', 'type': 'integer'}, 'b': {'title': 'B', 'type': 'integer'}}, 'required': ['a', 'b']}}}]}}\n",
      "Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'What is 2123 * 215123'}], 'model': 'gpt-3.5-turbo-0613', 'stream': False, 'temperature': 0.0, 'tools': [{'type': 'function', 'function': {'name': 'multiply', 'description': 'multiply(a: int, b: int) -> int\\nMultiple two integers and returns the result integer', 'parameters': {'type': 'object', 'properties': {'a': {'title': 'A', 'type': 'integer'}, 'b': {'title': 'B', 'type': 'integer'}}, 'required': ['a', 'b']}}}, {'type': 'function', 'function': {'name': 'add', 'description': 'add(a: int, b: int) -> int\\nAdd two integers and returns the result integer', 'parameters': {'type': 'object', 'properties': {'a': {'title': 'A', 'type': 'integer'}, 'b': {'title': 'B', 'type': 'integer'}}, 'required': ['a', 'b']}}}]}}\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=60.0 socket_options=None\n",
      "connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=60.0 socket_options=None\n",
      "connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=60.0 socket_options=None\n",
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4db8bb82e0>\n",
      "connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4db8bb82e0>\n",
      "connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4db8bb82e0>\n",
      "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x7f4db983bf40> server_hostname='api.openai.com' timeout=60.0\n",
      "start_tls.started ssl_context=<ssl.SSLContext object at 0x7f4db983bf40> server_hostname='api.openai.com' timeout=60.0\n",
      "start_tls.started ssl_context=<ssl.SSLContext object at 0x7f4db983bf40> server_hostname='api.openai.com' timeout=60.0\n",
      "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4db85daeb0>\n",
      "start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4db85daeb0>\n",
      "start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4db85daeb0>\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "send_request_headers.started request=<Request [b'POST']>\n",
      "send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "send_request_headers.complete\n",
      "send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "send_request_body.started request=<Request [b'POST']>\n",
      "send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "send_request_body.complete\n",
      "send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "receive_response_headers.started request=<Request [b'POST']>\n",
      "receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 07 Feb 2024 20:00:33 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-0613'), (b'openai-organization', b'user-vwb3grcawrxtbvbh7lve9ude'), (b'openai-processing-ms', b'2002'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'60000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'59977'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'23ms'), (b'x-request-id', b'44fe9b7958a7349351f5692da9a63831'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=MuzEgj95bUth1JADbaUbamd8FHNWBNovdiEL7SYIzP4-1707336033-1-AahRBB7YyV7KqCkbejKMhogOEH/vDoagAHsO9fsWreXE98wBVBr0xirNUXPaTQWkM3U+pYo1DSnZCF9o6VaqIGI=; path=/; expires=Wed, 07-Feb-24 20:30:33 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=QePqO.Xy8CbSYtkLjPCAxd8tguuKPF2bRuUttangknk-1707336033005-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'851e382fee686a8e-BRU'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 07 Feb 2024 20:00:33 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-0613'), (b'openai-organization', b'user-vwb3grcawrxtbvbh7lve9ude'), (b'openai-processing-ms', b'2002'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'60000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'59977'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'23ms'), (b'x-request-id', b'44fe9b7958a7349351f5692da9a63831'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=MuzEgj95bUth1JADbaUbamd8FHNWBNovdiEL7SYIzP4-1707336033-1-AahRBB7YyV7KqCkbejKMhogOEH/vDoagAHsO9fsWreXE98wBVBr0xirNUXPaTQWkM3U+pYo1DSnZCF9o6VaqIGI=; path=/; expires=Wed, 07-Feb-24 20:30:33 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=QePqO.Xy8CbSYtkLjPCAxd8tguuKPF2bRuUttangknk-1707336033005-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'851e382fee686a8e-BRU'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 07 Feb 2024 20:00:33 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-0613'), (b'openai-organization', b'user-vwb3grcawrxtbvbh7lve9ude'), (b'openai-processing-ms', b'2002'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'60000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'59977'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'23ms'), (b'x-request-id', b'44fe9b7958a7349351f5692da9a63831'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=MuzEgj95bUth1JADbaUbamd8FHNWBNovdiEL7SYIzP4-1707336033-1-AahRBB7YyV7KqCkbejKMhogOEH/vDoagAHsO9fsWreXE98wBVBr0xirNUXPaTQWkM3U+pYo1DSnZCF9o6VaqIGI=; path=/; expires=Wed, 07-Feb-24 20:30:33 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=QePqO.Xy8CbSYtkLjPCAxd8tguuKPF2bRuUttangknk-1707336033005-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'851e382fee686a8e-BRU'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "receive_response_body.started request=<Request [b'POST']>\n",
      "receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "receive_response_body.complete\n",
      "receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "response_closed.started\n",
      "response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "response_closed.complete\n",
      "response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Request: POST https://api.openai.com/v1/chat/completions \"200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"200 OK\"\n",
      "> Calling tool: multiply\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'What is 2123 * 215123'}, {'role': 'assistant', 'content': None, 'tool_calls': [{'id': 'call_XpHV4UJuDQZECQIrHzQMBoB1', 'function': {'arguments': '{\\n  \"a\": 2123,\\n  \"b\": 215123\\n}', 'name': 'multiply'}, 'type': 'function'}]}, {'role': 'tool', 'content': '456706129', 'tool_call_id': 'call_XpHV4UJuDQZECQIrHzQMBoB1', 'name': 'multiply'}], 'model': 'gpt-3.5-turbo-0613', 'stream': False, 'temperature': 0.0}}\n",
      "Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'What is 2123 * 215123'}, {'role': 'assistant', 'content': None, 'tool_calls': [{'id': 'call_XpHV4UJuDQZECQIrHzQMBoB1', 'function': {'arguments': '{\\n  \"a\": 2123,\\n  \"b\": 215123\\n}', 'name': 'multiply'}, 'type': 'function'}]}, {'role': 'tool', 'content': '456706129', 'tool_call_id': 'call_XpHV4UJuDQZECQIrHzQMBoB1', 'name': 'multiply'}], 'model': 'gpt-3.5-turbo-0613', 'stream': False, 'temperature': 0.0}}\n",
      "Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'What is 2123 * 215123'}, {'role': 'assistant', 'content': None, 'tool_calls': [{'id': 'call_XpHV4UJuDQZECQIrHzQMBoB1', 'function': {'arguments': '{\\n  \"a\": 2123,\\n  \"b\": 215123\\n}', 'name': 'multiply'}, 'type': 'function'}]}, {'role': 'tool', 'content': '456706129', 'tool_call_id': 'call_XpHV4UJuDQZECQIrHzQMBoB1', 'name': 'multiply'}], 'model': 'gpt-3.5-turbo-0613', 'stream': False, 'temperature': 0.0}}\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "send_request_headers.started request=<Request [b'POST']>\n",
      "send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "send_request_headers.complete\n",
      "send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "send_request_body.started request=<Request [b'POST']>\n",
      "send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "send_request_body.complete\n",
      "send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "receive_response_headers.started request=<Request [b'POST']>\n",
      "receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 07 Feb 2024 20:00:34 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-0613'), (b'openai-organization', b'user-vwb3grcawrxtbvbh7lve9ude'), (b'openai-processing-ms', b'1375'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'60000'), (b'x-ratelimit-remaining-requests', b'9998'), (b'x-ratelimit-remaining-tokens', b'59973'), (b'x-ratelimit-reset-requests', b'14.897s'), (b'x-ratelimit-reset-tokens', b'27ms'), (b'x-request-id', b'0eb73d022b7b761c7d405d50f428c608'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'851e383ed87e6a8e-BRU'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 07 Feb 2024 20:00:34 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-0613'), (b'openai-organization', b'user-vwb3grcawrxtbvbh7lve9ude'), (b'openai-processing-ms', b'1375'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'60000'), (b'x-ratelimit-remaining-requests', b'9998'), (b'x-ratelimit-remaining-tokens', b'59973'), (b'x-ratelimit-reset-requests', b'14.897s'), (b'x-ratelimit-reset-tokens', b'27ms'), (b'x-request-id', b'0eb73d022b7b761c7d405d50f428c608'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'851e383ed87e6a8e-BRU'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 07 Feb 2024 20:00:34 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-0613'), (b'openai-organization', b'user-vwb3grcawrxtbvbh7lve9ude'), (b'openai-processing-ms', b'1375'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'60000'), (b'x-ratelimit-remaining-requests', b'9998'), (b'x-ratelimit-remaining-tokens', b'59973'), (b'x-ratelimit-reset-requests', b'14.897s'), (b'x-ratelimit-reset-tokens', b'27ms'), (b'x-request-id', b'0eb73d022b7b761c7d405d50f428c608'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'851e383ed87e6a8e-BRU'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "receive_response_body.started request=<Request [b'POST']>\n",
      "receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "receive_response_body.complete\n",
      "receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "response_closed.started\n",
      "response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "response_closed.complete\n",
      "response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Request: POST https://api.openai.com/v1/chat/completions \"200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The product of 2123 multiplied by 215123 is 456,706,129.'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent = AIAgent(tools=[multiply_tool, add_tool])\n",
    "agent.chat(\"What is 2123 * 215123\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2338681e-e969-41f7-91f4-95d83cfe82aa",
   "metadata": {},
   "source": [
    "### OPENAIAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "752aaf6e-53a6-422f-9f48-f03aaeeb9940",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.agent import OpenAIAgent\n",
    "from llama_index.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo-0613\")\n",
    "agent = OpenAIAgent.from_tools(\n",
    "    [multiply_tool, add_tool], llm=llm, verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cb09982a-4b9c-469e-836a-a3a4d52d7422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: What is (121 * 3) + 42?\n",
      "DEBUG:httpx:load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "DEBUG:httpx:load_verify_locations cafile='/etc/ssl/certs/ca-certificates.crt'\n",
      "load_verify_locations cafile='/etc/ssl/certs/ca-certificates.crt'\n",
      "load_verify_locations cafile='/etc/ssl/certs/ca-certificates.crt'\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'What is (121 * 3) + 42?'}], 'model': 'gpt-3.5-turbo-0613', 'stream': False, 'temperature': 0.1, 'tool_choice': 'auto', 'tools': [{'type': 'function', 'function': {'name': 'multiply', 'description': 'multiply(a: int, b: int) -> int\\nMultiple two integers and returns the result integer', 'parameters': {'type': 'object', 'properties': {'a': {'title': 'A', 'type': 'integer'}, 'b': {'title': 'B', 'type': 'integer'}}, 'required': ['a', 'b']}}}, {'type': 'function', 'function': {'name': 'add', 'description': 'add(a: int, b: int) -> int\\nAdd two integers and returns the result integer', 'parameters': {'type': 'object', 'properties': {'a': {'title': 'A', 'type': 'integer'}, 'b': {'title': 'B', 'type': 'integer'}}, 'required': ['a', 'b']}}}]}}\n",
      "Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'What is (121 * 3) + 42?'}], 'model': 'gpt-3.5-turbo-0613', 'stream': False, 'temperature': 0.1, 'tool_choice': 'auto', 'tools': [{'type': 'function', 'function': {'name': 'multiply', 'description': 'multiply(a: int, b: int) -> int\\nMultiple two integers and returns the result integer', 'parameters': {'type': 'object', 'properties': {'a': {'title': 'A', 'type': 'integer'}, 'b': {'title': 'B', 'type': 'integer'}}, 'required': ['a', 'b']}}}, {'type': 'function', 'function': {'name': 'add', 'description': 'add(a: int, b: int) -> int\\nAdd two integers and returns the result integer', 'parameters': {'type': 'object', 'properties': {'a': {'title': 'A', 'type': 'integer'}, 'b': {'title': 'B', 'type': 'integer'}}, 'required': ['a', 'b']}}}]}}\n",
      "Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'What is (121 * 3) + 42?'}], 'model': 'gpt-3.5-turbo-0613', 'stream': False, 'temperature': 0.1, 'tool_choice': 'auto', 'tools': [{'type': 'function', 'function': {'name': 'multiply', 'description': 'multiply(a: int, b: int) -> int\\nMultiple two integers and returns the result integer', 'parameters': {'type': 'object', 'properties': {'a': {'title': 'A', 'type': 'integer'}, 'b': {'title': 'B', 'type': 'integer'}}, 'required': ['a', 'b']}}}, {'type': 'function', 'function': {'name': 'add', 'description': 'add(a: int, b: int) -> int\\nAdd two integers and returns the result integer', 'parameters': {'type': 'object', 'properties': {'a': {'title': 'A', 'type': 'integer'}, 'b': {'title': 'B', 'type': 'integer'}}, 'required': ['a', 'b']}}}]}}\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=60.0 socket_options=None\n",
      "connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=60.0 socket_options=None\n",
      "connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=60.0 socket_options=None\n",
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4db85daf70>\n",
      "connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4db85daf70>\n",
      "connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4db85daf70>\n",
      "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x7f4de068d1c0> server_hostname='api.openai.com' timeout=60.0\n",
      "start_tls.started ssl_context=<ssl.SSLContext object at 0x7f4de068d1c0> server_hostname='api.openai.com' timeout=60.0\n",
      "start_tls.started ssl_context=<ssl.SSLContext object at 0x7f4de068d1c0> server_hostname='api.openai.com' timeout=60.0\n",
      "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4db85dac10>\n",
      "start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4db85dac10>\n",
      "start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4db85dac10>\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "send_request_headers.started request=<Request [b'POST']>\n",
      "send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "send_request_headers.complete\n",
      "send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "send_request_body.started request=<Request [b'POST']>\n",
      "send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "send_request_body.complete\n",
      "send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "receive_response_headers.started request=<Request [b'POST']>\n",
      "receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 07 Feb 2024 20:03:02 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-0613'), (b'openai-organization', b'user-vwb3grcawrxtbvbh7lve9ude'), (b'openai-processing-ms', b'1280'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'60000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'59977'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'23ms'), (b'x-request-id', b'3a90be0aa47ffd0045fc866da756030b'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=HodmP4TjdinG5llZ_9L8TsxKWBcRQCB.dqLmCoLGpec-1707336182-1-AUfRGXYYIEFnGKHD6ZRfrAZpS1nR07QknojogoE4I77I8wTJIwkTNTcU366IkZLw50Axnwx0mIa0s0ZFSZud66Q=; path=/; expires=Wed, 07-Feb-24 20:33:02 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=trO2vRu14A93blM2LaY6qli7vA.acFtQxY82Zqda7fU-1707336182633-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'851e3bdb9eb86a8f-BRU'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 07 Feb 2024 20:03:02 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-0613'), (b'openai-organization', b'user-vwb3grcawrxtbvbh7lve9ude'), (b'openai-processing-ms', b'1280'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'60000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'59977'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'23ms'), (b'x-request-id', b'3a90be0aa47ffd0045fc866da756030b'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=HodmP4TjdinG5llZ_9L8TsxKWBcRQCB.dqLmCoLGpec-1707336182-1-AUfRGXYYIEFnGKHD6ZRfrAZpS1nR07QknojogoE4I77I8wTJIwkTNTcU366IkZLw50Axnwx0mIa0s0ZFSZud66Q=; path=/; expires=Wed, 07-Feb-24 20:33:02 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=trO2vRu14A93blM2LaY6qli7vA.acFtQxY82Zqda7fU-1707336182633-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'851e3bdb9eb86a8f-BRU'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 07 Feb 2024 20:03:02 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-0613'), (b'openai-organization', b'user-vwb3grcawrxtbvbh7lve9ude'), (b'openai-processing-ms', b'1280'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'60000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'59977'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'23ms'), (b'x-request-id', b'3a90be0aa47ffd0045fc866da756030b'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=HodmP4TjdinG5llZ_9L8TsxKWBcRQCB.dqLmCoLGpec-1707336182-1-AUfRGXYYIEFnGKHD6ZRfrAZpS1nR07QknojogoE4I77I8wTJIwkTNTcU366IkZLw50Axnwx0mIa0s0ZFSZud66Q=; path=/; expires=Wed, 07-Feb-24 20:33:02 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=trO2vRu14A93blM2LaY6qli7vA.acFtQxY82Zqda7fU-1707336182633-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'851e3bdb9eb86a8f-BRU'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "receive_response_body.started request=<Request [b'POST']>\n",
      "receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "receive_response_body.complete\n",
      "receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "response_closed.started\n",
      "response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "response_closed.complete\n",
      "response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Request: POST https://api.openai.com/v1/chat/completions \"200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"200 OK\"\n",
      "=== Calling Function ===\n",
      "Calling function: multiply with args: {\n",
      "  \"a\": 121,\n",
      "  \"b\": 3\n",
      "}\n",
      "Got output: 363\n",
      "========================\n",
      "\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'What is (121 * 3) + 42?'}, {'role': 'assistant', 'content': None, 'tool_calls': [{'id': 'call_U11J0eJZs4ngj5X8Nk9mLBk4', 'function': {'arguments': '{\\n  \"a\": 121,\\n  \"b\": 3\\n}', 'name': 'multiply'}, 'type': 'function'}]}, {'role': 'tool', 'content': '363', 'name': 'multiply', 'tool_call_id': 'call_U11J0eJZs4ngj5X8Nk9mLBk4'}], 'model': 'gpt-3.5-turbo-0613', 'stream': False, 'temperature': 0.1, 'tool_choice': 'auto', 'tools': [{'type': 'function', 'function': {'name': 'multiply', 'description': 'multiply(a: int, b: int) -> int\\nMultiple two integers and returns the result integer', 'parameters': {'type': 'object', 'properties': {'a': {'title': 'A', 'type': 'integer'}, 'b': {'title': 'B', 'type': 'integer'}}, 'required': ['a', 'b']}}}, {'type': 'function', 'function': {'name': 'add', 'description': 'add(a: int, b: int) -> int\\nAdd two integers and returns the result integer', 'parameters': {'type': 'object', 'properties': {'a': {'title': 'A', 'type': 'integer'}, 'b': {'title': 'B', 'type': 'integer'}}, 'required': ['a', 'b']}}}]}}\n",
      "Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'What is (121 * 3) + 42?'}, {'role': 'assistant', 'content': None, 'tool_calls': [{'id': 'call_U11J0eJZs4ngj5X8Nk9mLBk4', 'function': {'arguments': '{\\n  \"a\": 121,\\n  \"b\": 3\\n}', 'name': 'multiply'}, 'type': 'function'}]}, {'role': 'tool', 'content': '363', 'name': 'multiply', 'tool_call_id': 'call_U11J0eJZs4ngj5X8Nk9mLBk4'}], 'model': 'gpt-3.5-turbo-0613', 'stream': False, 'temperature': 0.1, 'tool_choice': 'auto', 'tools': [{'type': 'function', 'function': {'name': 'multiply', 'description': 'multiply(a: int, b: int) -> int\\nMultiple two integers and returns the result integer', 'parameters': {'type': 'object', 'properties': {'a': {'title': 'A', 'type': 'integer'}, 'b': {'title': 'B', 'type': 'integer'}}, 'required': ['a', 'b']}}}, {'type': 'function', 'function': {'name': 'add', 'description': 'add(a: int, b: int) -> int\\nAdd two integers and returns the result integer', 'parameters': {'type': 'object', 'properties': {'a': {'title': 'A', 'type': 'integer'}, 'b': {'title': 'B', 'type': 'integer'}}, 'required': ['a', 'b']}}}]}}\n",
      "Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'What is (121 * 3) + 42?'}, {'role': 'assistant', 'content': None, 'tool_calls': [{'id': 'call_U11J0eJZs4ngj5X8Nk9mLBk4', 'function': {'arguments': '{\\n  \"a\": 121,\\n  \"b\": 3\\n}', 'name': 'multiply'}, 'type': 'function'}]}, {'role': 'tool', 'content': '363', 'name': 'multiply', 'tool_call_id': 'call_U11J0eJZs4ngj5X8Nk9mLBk4'}], 'model': 'gpt-3.5-turbo-0613', 'stream': False, 'temperature': 0.1, 'tool_choice': 'auto', 'tools': [{'type': 'function', 'function': {'name': 'multiply', 'description': 'multiply(a: int, b: int) -> int\\nMultiple two integers and returns the result integer', 'parameters': {'type': 'object', 'properties': {'a': {'title': 'A', 'type': 'integer'}, 'b': {'title': 'B', 'type': 'integer'}}, 'required': ['a', 'b']}}}, {'type': 'function', 'function': {'name': 'add', 'description': 'add(a: int, b: int) -> int\\nAdd two integers and returns the result integer', 'parameters': {'type': 'object', 'properties': {'a': {'title': 'A', 'type': 'integer'}, 'b': {'title': 'B', 'type': 'integer'}}, 'required': ['a', 'b']}}}]}}\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "send_request_headers.started request=<Request [b'POST']>\n",
      "send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "send_request_headers.complete\n",
      "send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "send_request_body.started request=<Request [b'POST']>\n",
      "send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "send_request_body.complete\n",
      "send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "receive_response_headers.started request=<Request [b'POST']>\n",
      "receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 07 Feb 2024 20:03:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-0613'), (b'openai-organization', b'user-vwb3grcawrxtbvbh7lve9ude'), (b'openai-processing-ms', b'374'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'60000'), (b'x-ratelimit-remaining-requests', b'9998'), (b'x-ratelimit-remaining-tokens', b'59974'), (b'x-ratelimit-reset-requests', b'15.612s'), (b'x-ratelimit-reset-tokens', b'26ms'), (b'x-request-id', b'9a08a8ac05139404c227d18f9d5992e1'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'851e3be63fba6a8f-BRU'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 07 Feb 2024 20:03:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-0613'), (b'openai-organization', b'user-vwb3grcawrxtbvbh7lve9ude'), (b'openai-processing-ms', b'374'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'60000'), (b'x-ratelimit-remaining-requests', b'9998'), (b'x-ratelimit-remaining-tokens', b'59974'), (b'x-ratelimit-reset-requests', b'15.612s'), (b'x-ratelimit-reset-tokens', b'26ms'), (b'x-request-id', b'9a08a8ac05139404c227d18f9d5992e1'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'851e3be63fba6a8f-BRU'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 07 Feb 2024 20:03:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-0613'), (b'openai-organization', b'user-vwb3grcawrxtbvbh7lve9ude'), (b'openai-processing-ms', b'374'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'60000'), (b'x-ratelimit-remaining-requests', b'9998'), (b'x-ratelimit-remaining-tokens', b'59974'), (b'x-ratelimit-reset-requests', b'15.612s'), (b'x-ratelimit-reset-tokens', b'26ms'), (b'x-request-id', b'9a08a8ac05139404c227d18f9d5992e1'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'851e3be63fba6a8f-BRU'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "receive_response_body.started request=<Request [b'POST']>\n",
      "receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "receive_response_body.complete\n",
      "receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "response_closed.started\n",
      "response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "response_closed.complete\n",
      "response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Request: POST https://api.openai.com/v1/chat/completions \"200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"200 OK\"\n",
      "=== Calling Function ===\n",
      "Calling function: add with args: {\n",
      "  \"a\": 363,\n",
      "  \"b\": 42\n",
      "}\n",
      "Got output: 405\n",
      "========================\n",
      "\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'What is (121 * 3) + 42?'}, {'role': 'assistant', 'content': None, 'tool_calls': [{'id': 'call_U11J0eJZs4ngj5X8Nk9mLBk4', 'function': {'arguments': '{\\n  \"a\": 121,\\n  \"b\": 3\\n}', 'name': 'multiply'}, 'type': 'function'}]}, {'role': 'tool', 'content': '363', 'name': 'multiply', 'tool_call_id': 'call_U11J0eJZs4ngj5X8Nk9mLBk4'}, {'role': 'assistant', 'content': None, 'tool_calls': [{'id': 'call_OA0ZMwF2V2XvXEjRvXcYz7ju', 'function': {'arguments': '{\\n  \"a\": 363,\\n  \"b\": 42\\n}', 'name': 'add'}, 'type': 'function'}]}, {'role': 'tool', 'content': '405', 'name': 'add', 'tool_call_id': 'call_OA0ZMwF2V2XvXEjRvXcYz7ju'}], 'model': 'gpt-3.5-turbo-0613', 'stream': False, 'temperature': 0.1, 'tool_choice': 'auto', 'tools': [{'type': 'function', 'function': {'name': 'multiply', 'description': 'multiply(a: int, b: int) -> int\\nMultiple two integers and returns the result integer', 'parameters': {'type': 'object', 'properties': {'a': {'title': 'A', 'type': 'integer'}, 'b': {'title': 'B', 'type': 'integer'}}, 'required': ['a', 'b']}}}, {'type': 'function', 'function': {'name': 'add', 'description': 'add(a: int, b: int) -> int\\nAdd two integers and returns the result integer', 'parameters': {'type': 'object', 'properties': {'a': {'title': 'A', 'type': 'integer'}, 'b': {'title': 'B', 'type': 'integer'}}, 'required': ['a', 'b']}}}]}}\n",
      "Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'What is (121 * 3) + 42?'}, {'role': 'assistant', 'content': None, 'tool_calls': [{'id': 'call_U11J0eJZs4ngj5X8Nk9mLBk4', 'function': {'arguments': '{\\n  \"a\": 121,\\n  \"b\": 3\\n}', 'name': 'multiply'}, 'type': 'function'}]}, {'role': 'tool', 'content': '363', 'name': 'multiply', 'tool_call_id': 'call_U11J0eJZs4ngj5X8Nk9mLBk4'}, {'role': 'assistant', 'content': None, 'tool_calls': [{'id': 'call_OA0ZMwF2V2XvXEjRvXcYz7ju', 'function': {'arguments': '{\\n  \"a\": 363,\\n  \"b\": 42\\n}', 'name': 'add'}, 'type': 'function'}]}, {'role': 'tool', 'content': '405', 'name': 'add', 'tool_call_id': 'call_OA0ZMwF2V2XvXEjRvXcYz7ju'}], 'model': 'gpt-3.5-turbo-0613', 'stream': False, 'temperature': 0.1, 'tool_choice': 'auto', 'tools': [{'type': 'function', 'function': {'name': 'multiply', 'description': 'multiply(a: int, b: int) -> int\\nMultiple two integers and returns the result integer', 'parameters': {'type': 'object', 'properties': {'a': {'title': 'A', 'type': 'integer'}, 'b': {'title': 'B', 'type': 'integer'}}, 'required': ['a', 'b']}}}, {'type': 'function', 'function': {'name': 'add', 'description': 'add(a: int, b: int) -> int\\nAdd two integers and returns the result integer', 'parameters': {'type': 'object', 'properties': {'a': {'title': 'A', 'type': 'integer'}, 'b': {'title': 'B', 'type': 'integer'}}, 'required': ['a', 'b']}}}]}}\n",
      "Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'What is (121 * 3) + 42?'}, {'role': 'assistant', 'content': None, 'tool_calls': [{'id': 'call_U11J0eJZs4ngj5X8Nk9mLBk4', 'function': {'arguments': '{\\n  \"a\": 121,\\n  \"b\": 3\\n}', 'name': 'multiply'}, 'type': 'function'}]}, {'role': 'tool', 'content': '363', 'name': 'multiply', 'tool_call_id': 'call_U11J0eJZs4ngj5X8Nk9mLBk4'}, {'role': 'assistant', 'content': None, 'tool_calls': [{'id': 'call_OA0ZMwF2V2XvXEjRvXcYz7ju', 'function': {'arguments': '{\\n  \"a\": 363,\\n  \"b\": 42\\n}', 'name': 'add'}, 'type': 'function'}]}, {'role': 'tool', 'content': '405', 'name': 'add', 'tool_call_id': 'call_OA0ZMwF2V2XvXEjRvXcYz7ju'}], 'model': 'gpt-3.5-turbo-0613', 'stream': False, 'temperature': 0.1, 'tool_choice': 'auto', 'tools': [{'type': 'function', 'function': {'name': 'multiply', 'description': 'multiply(a: int, b: int) -> int\\nMultiple two integers and returns the result integer', 'parameters': {'type': 'object', 'properties': {'a': {'title': 'A', 'type': 'integer'}, 'b': {'title': 'B', 'type': 'integer'}}, 'required': ['a', 'b']}}}, {'type': 'function', 'function': {'name': 'add', 'description': 'add(a: int, b: int) -> int\\nAdd two integers and returns the result integer', 'parameters': {'type': 'object', 'properties': {'a': {'title': 'A', 'type': 'integer'}, 'b': {'title': 'B', 'type': 'integer'}}, 'required': ['a', 'b']}}}]}}\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "send_request_headers.started request=<Request [b'POST']>\n",
      "send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "send_request_headers.complete\n",
      "send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "send_request_body.started request=<Request [b'POST']>\n",
      "send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "send_request_body.complete\n",
      "send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "receive_response_headers.started request=<Request [b'POST']>\n",
      "receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 07 Feb 2024 20:03:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-0613'), (b'openai-organization', b'user-vwb3grcawrxtbvbh7lve9ude'), (b'openai-processing-ms', b'354'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'60000'), (b'x-ratelimit-remaining-requests', b'9997'), (b'x-ratelimit-remaining-tokens', b'59971'), (b'x-ratelimit-reset-requests', b'23.597s'), (b'x-ratelimit-reset-tokens', b'29ms'), (b'x-request-id', b'7e22ab466d8e16b4003ab5868a8eb0d9'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'851e3bea38b86a8f-BRU'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 07 Feb 2024 20:03:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-0613'), (b'openai-organization', b'user-vwb3grcawrxtbvbh7lve9ude'), (b'openai-processing-ms', b'354'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'60000'), (b'x-ratelimit-remaining-requests', b'9997'), (b'x-ratelimit-remaining-tokens', b'59971'), (b'x-ratelimit-reset-requests', b'23.597s'), (b'x-ratelimit-reset-tokens', b'29ms'), (b'x-request-id', b'7e22ab466d8e16b4003ab5868a8eb0d9'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'851e3bea38b86a8f-BRU'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 07 Feb 2024 20:03:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-0613'), (b'openai-organization', b'user-vwb3grcawrxtbvbh7lve9ude'), (b'openai-processing-ms', b'354'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'60000'), (b'x-ratelimit-remaining-requests', b'9997'), (b'x-ratelimit-remaining-tokens', b'59971'), (b'x-ratelimit-reset-requests', b'23.597s'), (b'x-ratelimit-reset-tokens', b'29ms'), (b'x-request-id', b'7e22ab466d8e16b4003ab5868a8eb0d9'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'851e3bea38b86a8f-BRU'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "receive_response_body.started request=<Request [b'POST']>\n",
      "receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "receive_response_body.complete\n",
      "receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "response_closed.started\n",
      "response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "response_closed.complete\n",
      "response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Request: POST https://api.openai.com/v1/chat/completions \"200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"200 OK\"\n",
      "(121 * 3) + 42 = 405\n"
     ]
    }
   ],
   "source": [
    "response = agent.chat(\"What is (121 * 3) + 42?\")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97a0141-c49d-4372-a5f6-34e0672fb740",
   "metadata": {},
   "source": [
    "### Agent with personality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "edd2d079-50e2-47b3-a714-7757fabe7498",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.prompts.system import SHAKESPEARE_WRITING_ASSISTANT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0bc68401-411a-4227-b718-54b6a0aeae0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: Tell me a story\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a Shakespearean writing assistant who speaks in a Shakespearean style. You help people come up with creative ideas and content like stories, poems, and songs that use Shakespearean style of writing style, including words like \"thou\" and \"hath”.\\nHere are some example of Shakespeare\\'s style:\\n - Romeo, Romeo! Wherefore art thou Romeo?\\n - Love looks not with the eyes, but with the mind; and therefore is winged Cupid painted blind.\\n - Shall I compare thee to a summer\\'s day? Thou art more lovely and more temperate.\\n'}, {'role': 'user', 'content': 'Tell me a story'}], 'model': 'gpt-3.5-turbo-0613', 'stream': False, 'temperature': 0.1, 'tool_choice': 'auto', 'tools': [{'type': 'function', 'function': {'name': 'multiply', 'description': 'multiply(a: int, b: int) -> int\\nMultiple two integers and returns the result integer', 'parameters': {'type': 'object', 'properties': {'a': {'title': 'A', 'type': 'integer'}, 'b': {'title': 'B', 'type': 'integer'}}, 'required': ['a', 'b']}}}, {'type': 'function', 'function': {'name': 'add', 'description': 'add(a: int, b: int) -> int\\nAdd two integers and returns the result integer', 'parameters': {'type': 'object', 'properties': {'a': {'title': 'A', 'type': 'integer'}, 'b': {'title': 'B', 'type': 'integer'}}, 'required': ['a', 'b']}}}]}}\n",
      "Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a Shakespearean writing assistant who speaks in a Shakespearean style. You help people come up with creative ideas and content like stories, poems, and songs that use Shakespearean style of writing style, including words like \"thou\" and \"hath”.\\nHere are some example of Shakespeare\\'s style:\\n - Romeo, Romeo! Wherefore art thou Romeo?\\n - Love looks not with the eyes, but with the mind; and therefore is winged Cupid painted blind.\\n - Shall I compare thee to a summer\\'s day? Thou art more lovely and more temperate.\\n'}, {'role': 'user', 'content': 'Tell me a story'}], 'model': 'gpt-3.5-turbo-0613', 'stream': False, 'temperature': 0.1, 'tool_choice': 'auto', 'tools': [{'type': 'function', 'function': {'name': 'multiply', 'description': 'multiply(a: int, b: int) -> int\\nMultiple two integers and returns the result integer', 'parameters': {'type': 'object', 'properties': {'a': {'title': 'A', 'type': 'integer'}, 'b': {'title': 'B', 'type': 'integer'}}, 'required': ['a', 'b']}}}, {'type': 'function', 'function': {'name': 'add', 'description': 'add(a: int, b: int) -> int\\nAdd two integers and returns the result integer', 'parameters': {'type': 'object', 'properties': {'a': {'title': 'A', 'type': 'integer'}, 'b': {'title': 'B', 'type': 'integer'}}, 'required': ['a', 'b']}}}]}}\n",
      "Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a Shakespearean writing assistant who speaks in a Shakespearean style. You help people come up with creative ideas and content like stories, poems, and songs that use Shakespearean style of writing style, including words like \"thou\" and \"hath”.\\nHere are some example of Shakespeare\\'s style:\\n - Romeo, Romeo! Wherefore art thou Romeo?\\n - Love looks not with the eyes, but with the mind; and therefore is winged Cupid painted blind.\\n - Shall I compare thee to a summer\\'s day? Thou art more lovely and more temperate.\\n'}, {'role': 'user', 'content': 'Tell me a story'}], 'model': 'gpt-3.5-turbo-0613', 'stream': False, 'temperature': 0.1, 'tool_choice': 'auto', 'tools': [{'type': 'function', 'function': {'name': 'multiply', 'description': 'multiply(a: int, b: int) -> int\\nMultiple two integers and returns the result integer', 'parameters': {'type': 'object', 'properties': {'a': {'title': 'A', 'type': 'integer'}, 'b': {'title': 'B', 'type': 'integer'}}, 'required': ['a', 'b']}}}, {'type': 'function', 'function': {'name': 'add', 'description': 'add(a: int, b: int) -> int\\nAdd two integers and returns the result integer', 'parameters': {'type': 'object', 'properties': {'a': {'title': 'A', 'type': 'integer'}, 'b': {'title': 'B', 'type': 'integer'}}, 'required': ['a', 'b']}}}]}}\n",
      "DEBUG:httpcore.connection:close.started\n",
      "close.started\n",
      "close.started\n",
      "DEBUG:httpcore.connection:close.complete\n",
      "close.complete\n",
      "close.complete\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=60.0 socket_options=None\n",
      "connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=60.0 socket_options=None\n",
      "connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=60.0 socket_options=None\n",
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4dafe09e20>\n",
      "connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4dafe09e20>\n",
      "connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4dafe09e20>\n",
      "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x7f4de068d1c0> server_hostname='api.openai.com' timeout=60.0\n",
      "start_tls.started ssl_context=<ssl.SSLContext object at 0x7f4de068d1c0> server_hostname='api.openai.com' timeout=60.0\n",
      "start_tls.started ssl_context=<ssl.SSLContext object at 0x7f4de068d1c0> server_hostname='api.openai.com' timeout=60.0\n",
      "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4dafe09910>\n",
      "start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4dafe09910>\n",
      "start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4dafe09910>\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "send_request_headers.started request=<Request [b'POST']>\n",
      "send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "send_request_headers.complete\n",
      "send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "send_request_body.started request=<Request [b'POST']>\n",
      "send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "send_request_body.complete\n",
      "send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "receive_response_headers.started request=<Request [b'POST']>\n",
      "receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 07 Feb 2024 20:04:19 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-0613'), (b'openai-organization', b'user-vwb3grcawrxtbvbh7lve9ude'), (b'openai-processing-ms', b'4899'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'60000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'59847'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'153ms'), (b'x-request-id', b'5526d633b730c24b8c767155feeb71f5'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'851e3da448552dd6-BRU'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 07 Feb 2024 20:04:19 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-0613'), (b'openai-organization', b'user-vwb3grcawrxtbvbh7lve9ude'), (b'openai-processing-ms', b'4899'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'60000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'59847'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'153ms'), (b'x-request-id', b'5526d633b730c24b8c767155feeb71f5'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'851e3da448552dd6-BRU'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 07 Feb 2024 20:04:19 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-0613'), (b'openai-organization', b'user-vwb3grcawrxtbvbh7lve9ude'), (b'openai-processing-ms', b'4899'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'60000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'59847'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'153ms'), (b'x-request-id', b'5526d633b730c24b8c767155feeb71f5'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'851e3da448552dd6-BRU'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "receive_response_body.started request=<Request [b'POST']>\n",
      "receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "receive_response_body.complete\n",
      "receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "response_closed.started\n",
      "response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "response_closed.complete\n",
      "response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Request: POST https://api.openai.com/v1/chat/completions \"200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"200 OK\"\n",
      "Once upon a time, in fair Verona's land,\n",
      "Where two households, both alike in dignity,\n",
      "A tale of love and tragedy did unfold,\n",
      "With passion, feuds, and destiny.\n",
      "\n",
      "In fair Verona, where we lay our scene,\n",
      "There lived a young and noble Montague,\n",
      "His name was Romeo, a lad of sixteen,\n",
      "With a heart so pure and love so true.\n",
      "\n",
      "And in fair Verona, there dwelled a maiden fair,\n",
      "Juliet, the daughter of Capulet,\n",
      "Her beauty unmatched, beyond compare,\n",
      "A rose in the garden, a jewel in the sunset.\n",
      "\n",
      "But alas, their families were sworn enemies,\n",
      "A feud that spanned generations past,\n",
      "Yet love knows no boundaries, no boundaries,\n",
      "And their hearts were bound, forever to last.\n",
      "\n",
      "'Twas at a masquerade ball, where fate did intervene,\n",
      "Romeo and Juliet's eyes did meet,\n",
      "A love so forbidden, yet so serene,\n",
      "Their souls entwined, destiny complete.\n",
      "\n",
      "Underneath the moonlit sky, they did confess,\n",
      "Their love for one another, pure and true,\n",
      "But the stars above, they did not bless,\n",
      "For their love would face trials, through and through.\n",
      "\n",
      "Their secret love, like a flame, burned bright,\n",
      "But the world around them, it did conspire,\n",
      "With schemes and plots, darkness took flight,\n",
      "And their love was tested, consumed by fire.\n",
      "\n",
      "A tragic twist of fate, a fatal mistake,\n",
      "A duel between Tybalt and Romeo,\n",
      "Blood was shed, lives were at stake,\n",
      "And the seeds of tragedy began to sow.\n",
      "\n",
      "Banished from Verona, Romeo did flee,\n",
      "Leaving Juliet behind, broken and alone,\n",
      "But love knows no bounds, no boundaries,\n",
      "And their hearts remained forever entwined, never to disown.\n",
      "\n",
      "In her despair, Juliet sought a way,\n",
      "To be reunited with her love, her Romeo,\n",
      "A potion she drank, to sleep and lay,\n",
      "In a tomb, where death's embrace would bestow.\n",
      "\n",
      "But fate had other plans, a cruel twist,\n",
      "Romeo, unaware of the potion's effect,\n",
      "Arrived at the tomb, his heart amiss,\n",
      "And saw his love, lifeless and bereft.\n",
      "\n",
      "In sorrow and despair, Romeo took his life,\n",
      "A tragic end to a love so pure,\n",
      "And upon awakening, Juliet faced the strife,\n",
      "To find her love gone, her heart unsure.\n",
      "\n",
      "In death, they found their eternal peace,\n",
      "Their love immortalized, a tragic tale,\n",
      "A reminder that love's flame will never cease,\n",
      "Even when faced with a world so frail.\n",
      "\n",
      "And so, in fair Verona's land,\n",
      "Their story lives on, through the ages,\n",
      "A tale of love, destiny, and a fate so grand,\n",
      "Written in the pages of Shakespeare's stages.\n"
     ]
    }
   ],
   "source": [
    "agent = OpenAIAgent.from_tools(\n",
    "    [multiply_tool, add_tool],\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    system_prompt=SHAKESPEARE_WRITING_ASSISTANT,\n",
    ")\n",
    "\n",
    "response = agent.chat(\"Tell me a story\")\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
